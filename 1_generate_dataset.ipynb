{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "def noise(noise_level, shape):\n",
    "    return np.random.choice([0, 1], shape, p=[1-noise_level, noise_level])\n",
    "\n",
    "def noise_masks(noise_levels, shape):\n",
    "    return [noise(noise_level, shape) for noise_level in noise_levels]\n",
    "\n",
    "def noisy_images(image_filename, min_noise, max_noise, count):\n",
    "    image = scipy.misc.imread(image_filename, flatten=True)/255\n",
    "    noise_levels = np.linspace(min_noise, max_noise, count)\n",
    "    return [np.logical_xor(image, noise_mask) for noise_mask in noise_masks(noise_levels, np.shape(image))]\n",
    "\n",
    "def random_images(min_noise, max_noise, count, shape):\n",
    "    noise_levels = np.linspace(min_noise, max_noise, count)\n",
    "    return noise_masks(noise_levels, shape)\n",
    "\n",
    "def flatten(matrix_array):\n",
    "    return [matrix.flatten() for matrix in matrix_array]\n",
    "\n",
    "def generate_dataset():\n",
    "    import os    \n",
    "    files = os.listdir('patterns')\n",
    "\n",
    "    count = 100\n",
    "\n",
    "    images = []\n",
    "    for file in files:\n",
    "        images += noisy_images('patterns/' + file, 0, 0.4, count)\n",
    "    images += random_images(0.1, 0.9, count, np.shape(images[0]))\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(files) + 1):\n",
    "        labels += [i] * count\n",
    "\n",
    "    return flatten(images), labels\n",
    "\n",
    "x, y = generate_dataset()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump([x_train, x_test, y_train, y_test], 'dataset.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
